"""
Vector Store Manager / å‘é‡å­˜å‚¨ç®¡ç†å™¨
=====================================

åŸºäº LlamaIndex çš„ Milvus å‘é‡å­˜å‚¨å®ç°ã€‚

æ ¸å¿ƒåŠŸèƒ½
--------
1. **æ–‡æ¡£å­˜å‚¨**: å°†æ–‡æ¡£åµŒå…¥å‘é‡å­˜å…¥ Milvus
2. **ç›¸ä¼¼åº¦æ£€ç´¢**: åŸºäºå‘é‡çš„è¯­ä¹‰æœç´¢
3. **æ··åˆæ£€ç´¢**: æ”¯æŒä¸ BM25 ç»“åˆä½¿ç”¨
4. **åŒæ¡†æ¶å…¼å®¹**: åŒæ—¶æ”¯æŒ LlamaIndex å’Œ LangChain
5. **Langfuse è¿½è¸ª**: è‡ªåŠ¨è®°å½•åµŒå…¥å’Œæ£€ç´¢æ“ä½œ

æ¶æ„è¯´æ˜
--------
```
LlamaIndex TextNode/Document
           â†“
    OllamaEmbedding (åµŒå…¥) â†’ Langfuse Span
           â†“
    MilvusVectorStore (å­˜å‚¨)
           â†“
    VectorStoreIndex (ç´¢å¼•)
           â†“
    VectorIndexRetriever (æ£€ç´¢) â†’ Langfuse Span
```

Langfuse è¿½è¸ª
-------------
```
Trace: vector_store_operation
â”œâ”€â”€ Span: embedding
â”‚   â”œâ”€â”€ model
â”‚   â”œâ”€â”€ num_texts
â”‚   â””â”€â”€ elapsed_time
â””â”€â”€ Span: retrieval
    â”œâ”€â”€ query
    â”œâ”€â”€ top_k
    â”œâ”€â”€ num_results
    â””â”€â”€ scores
```

é…ç½®å‚æ•°
--------
```python
# config/settings.py
MILVUS_HOST = "localhost"
MILVUS_PORT = 19530
MILVUS_COLLECTION = "customer_service_kb"
EMBEDDING_MODEL = "nomic-embed-text"
EMBEDDING_BASE_URL = "http://localhost:11434"
LANGFUSE_ENABLED = True
```

ä½¿ç”¨ç¤ºä¾‹
--------
```python
from app.core.vector_store import VectorStoreManager

# åˆå§‹åŒ–
manager = VectorStoreManager()

# æ·»åŠ  LlamaIndex èŠ‚ç‚¹
manager.add_nodes(nodes)

# æ·»åŠ  LangChain æ–‡æ¡£ (è‡ªåŠ¨è½¬æ¢)
manager.add_documents(langchain_docs)

# æ£€ç´¢
results = manager.retrieve("æŸ¥è¯¢é—®é¢˜", top_k=5)

# è·å– LlamaIndex ç´¢å¼• (ç”¨äº RAG ç®¡é“)
index = manager.get_index()
```

Author: Intelligent Customer Service Team
Version: 2.1.0 (LlamaIndex + Langfuse)
"""
import logging
import time
from typing import List, Dict, Any, Optional, Union

from llama_index.core import (
    VectorStoreIndex,
    StorageContext,
    Settings as LlamaSettings,
)
from llama_index.core.schema import TextNode, NodeWithScore, BaseNode
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.vector_stores.milvus import MilvusVectorStore
from llama_index.embeddings.ollama import OllamaEmbedding

# LangChain å…¼å®¹
from langchain_core.documents import Document as LangchainDocument
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun

from config.settings import settings

# Langfuse observability
from app.services.langfuse_service import get_langfuse_service

logger = logging.getLogger(__name__)


class VectorStoreRetriever(BaseRetriever):
    """
    LangChain BaseRetriever å®ç°ã€‚

    ç»§æ‰¿è‡ª BaseRetriever ä»¥ç¡®ä¿ä¸ LCEL é“¾å…¼å®¹ã€‚

    Attributes
    ----------
    manager : Any
        VectorStoreManager å®ä¾‹å¼•ç”¨
    top_k : int
        è¿”å›ç»“æœæ•°é‡
    """

    manager: Any  # VectorStoreManager instance
    top_k: int = 5

    class Config:
        arbitrary_types_allowed = True

    def _get_relevant_documents(
        self,
        query: str,
        *,
        run_manager: Optional[CallbackManagerForRetrieverRun] = None,
    ) -> List[LangchainDocument]:
        """
        è·å–ç›¸å…³æ–‡æ¡£ã€‚

        Parameters
        ----------
        query : str
            æŸ¥è¯¢æ–‡æœ¬
        run_manager : CallbackManagerForRetrieverRun, optional
            å›è°ƒç®¡ç†å™¨

        Returns
        -------
        List[LangchainDocument]
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        return self.manager.similarity_search(query, k=self.top_k)


class VectorStoreManager:
    """
    å‘é‡å­˜å‚¨ç®¡ç†å™¨ (LlamaIndex + Milvus)
    ===================================

    ç®¡ç† Milvus å‘é‡æ•°æ®åº“çš„è¿æ¥ã€ç´¢å¼•å’Œæ£€ç´¢æ“ä½œã€‚

    Attributes
    ----------
    host : str
        Milvus æœåŠ¡å™¨åœ°å€

    port : int
        Milvus ç«¯å£

    collection_name : str
        é›†åˆåç§°

    embed_model : OllamaEmbedding
        åµŒå…¥æ¨¡å‹å®ä¾‹

    vector_store : MilvusVectorStore
        Milvus å‘é‡å­˜å‚¨å®ä¾‹

    Example
    -------
    ```python
    manager = VectorStoreManager(
        host="localhost",
        port=19530,
        collection_name="my_kb"
    )

    # æ·»åŠ æ–‡æ¡£
    manager.add_nodes(nodes)

    # æ£€ç´¢
    results = manager.retrieve("é—®é¢˜", top_k=5)
    for node in results:
        print(f"Score: {node.score}, Text: {node.text[:100]}")
    ```
    """

    def __init__(
        self,
        host: str = None,
        port: int = None,
        collection_name: str = None,
        embedding_model: str = None,
        embedding_base_url: str = None,
        database: str = None,
        dim: int = 768,
    ):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨ã€‚

        Parameters
        ----------
        host : str, optional
            Milvus åœ°å€ï¼Œé»˜è®¤ä½¿ç”¨ settings.MILVUS_HOST

        port : int, optional
            Milvus ç«¯å£ï¼Œé»˜è®¤ä½¿ç”¨ settings.MILVUS_PORT

        collection_name : str, optional
            é›†åˆåç§°ï¼Œé»˜è®¤ä½¿ç”¨ settings.MILVUS_COLLECTION

        embedding_model : str, optional
            åµŒå…¥æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ settings.EMBEDDING_MODEL

        embedding_base_url : str, optional
            Ollama åœ°å€ï¼Œé»˜è®¤ä½¿ç”¨ settings.EMBEDDING_BASE_URL

        database : str, optional
            æ•°æ®åº“åç§°

        dim : int, optional
            å‘é‡ç»´åº¦ï¼Œé»˜è®¤ 768
        """
        self.host = host or settings.MILVUS_HOST
        self.port = port or settings.MILVUS_PORT
        self.collection_name = collection_name or settings.MILVUS_COLLECTION
        self.database = database or settings.MILVUS_DATABASE
        self.dim = dim

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embed_model = OllamaEmbedding(
            model_name=embedding_model or settings.EMBEDDING_MODEL,
            base_url=embedding_base_url or settings.EMBEDDING_BASE_URL,
        )

        # è®¾ç½®å…¨å±€åµŒå…¥æ¨¡å‹
        LlamaSettings.embed_model = self.embed_model

        # å»¶è¿Ÿåˆå§‹åŒ–
        self._vector_store: Optional[MilvusVectorStore] = None
        self._index: Optional[VectorStoreIndex] = None

        logger.info(
            f"[VectorStore] Initialized - host: {self.host}:{self.port}, "
            f"collection: {self.collection_name}"
        )

    def _get_vector_store(self, overwrite: bool = False) -> MilvusVectorStore:
        """
        è·å–æˆ–åˆ›å»º Milvus å‘é‡å­˜å‚¨ã€‚

        Parameters
        ----------
        overwrite : bool
            æ˜¯å¦è¦†ç›–ç°æœ‰é›†åˆ

        Returns
        -------
        MilvusVectorStore
            å‘é‡å­˜å‚¨å®ä¾‹
        """
        if self._vector_store is None or overwrite:
            try:
                uri = f"http://{self.host}:{self.port}"

                self._vector_store = MilvusVectorStore(
                    uri=uri,
                    collection_name=self.collection_name,
                    dim=self.dim,
                    overwrite=overwrite,
                    embedding_field="vector",  # Match existing Milvus schema
                    text_key="text",  # Match existing Milvus schema
                )

                logger.info(
                    f"[VectorStore] Connected to Milvus: {uri}, "
                    f"collection: {self.collection_name}"
                )
            except Exception as e:
                logger.error(f"[VectorStore] Failed to connect to Milvus: {e}")
                raise

        return self._vector_store

    @property
    def vector_store(self) -> MilvusVectorStore:
        """è·å–å‘é‡å­˜å‚¨å®ä¾‹ã€‚"""
        return self._get_vector_store()

    def _get_index(self, nodes: Optional[List[BaseNode]] = None) -> VectorStoreIndex:
        """
        è·å–æˆ–åˆ›å»ºå‘é‡ç´¢å¼•ã€‚

        Parameters
        ----------
        nodes : List[BaseNode], optional
            è¦æ·»åŠ çš„èŠ‚ç‚¹åˆ—è¡¨

        Returns
        -------
        VectorStoreIndex
            å‘é‡ç´¢å¼•å®ä¾‹
        """
        if self._index is None:
            storage_context = StorageContext.from_defaults(
                vector_store=self.vector_store
            )

            if nodes:
                self._index = VectorStoreIndex(
                    nodes=nodes,
                    storage_context=storage_context,
                    embed_model=self.embed_model,
                )
            else:
                # ä»ç°æœ‰å­˜å‚¨åˆ›å»ºç´¢å¼•
                self._index = VectorStoreIndex.from_vector_store(
                    vector_store=self.vector_store,
                    embed_model=self.embed_model,
                )

        return self._index

    def get_index(self) -> VectorStoreIndex:
        """
        è·å–å‘é‡ç´¢å¼•ï¼ˆç”¨äº RAG ç®¡é“ï¼‰ã€‚

        Returns
        -------
        VectorStoreIndex
            å¯ç”¨äºæ„å»ºæŸ¥è¯¢å¼•æ“çš„ç´¢å¼•

        Example
        -------
        ```python
        index = manager.get_index()
        query_engine = index.as_query_engine()
        response = query_engine.query("é—®é¢˜")
        ```
        """
        return self._get_index()

    def add_nodes(
        self,
        nodes: List[BaseNode],
        overwrite: bool = False,
        trace=None,
    ) -> List[str]:
        """
        æ·»åŠ  LlamaIndex èŠ‚ç‚¹åˆ°å‘é‡å­˜å‚¨ã€‚

        Parameters
        ----------
        nodes : List[BaseNode]
            TextNode æˆ–å…¶ä»– BaseNode åˆ—è¡¨

        overwrite : bool
            æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®

        trace : Langfuse Trace, optional
            Langfuse è¿½è¸ªå¯¹è±¡

        Returns
        -------
        List[str]
            èŠ‚ç‚¹ ID åˆ—è¡¨

        Example
        -------
        ```python
        nodes = [
            TextNode(text="æ–‡æ¡£å†…å®¹1", metadata={"source": "doc1"}),
            TextNode(text="æ–‡æ¡£å†…å®¹2", metadata={"source": "doc2"}),
        ]
        ids = manager.add_nodes(nodes)
        ```
        """
        if not nodes:
            return []

        total_chars = sum(len(n.get_content()) for n in nodes)
        logger.info(f"[VectorStore] ========== å¼€å§‹å‘é‡åµŒå…¥ ==========")
        logger.info(f"[VectorStore] ğŸ“Š èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        logger.info(f"[VectorStore] ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars:,} å­—ç¬¦")
        logger.info(f"[VectorStore] ğŸ”§ åµŒå…¥æ¨¡å‹: {settings.EMBEDDING_MODEL}")
        logger.info(f"[VectorStore] ğŸ“¦ Milvus é›†åˆ: {self.collection_name}")
        logger.info(f"[VectorStore] ğŸ”„ è¦†ç›–æ¨¡å¼: {'æ˜¯' if overwrite else 'å¦'}")

        # Langfuse è¿½è¸ª
        langfuse = get_langfuse_service()
        span = None
        if trace:
            span = langfuse.create_span(
                trace,
                name="vector_store_add",
                input={
                    "num_nodes": len(nodes),
                    "overwrite": overwrite,
                    "total_chars": total_chars,
                },
                metadata={
                    "collection": self.collection_name,
                    "embedding_model": settings.EMBEDDING_MODEL,
                },
            )

        start_time = time.time()

        try:
            if overwrite:
                self._vector_store = None
                self._index = None

            # åˆ›å»ºæˆ–æ›´æ–°ç´¢å¼•
            logger.info(f"[VectorStore] ğŸš€ å¼€å§‹ç”ŸæˆåµŒå…¥å‘é‡...")
            storage_context = StorageContext.from_defaults(
                vector_store=self._get_vector_store(overwrite=overwrite)
            )

            self._index = VectorStoreIndex(
                nodes=nodes,
                storage_context=storage_context,
                embed_model=self.embed_model,
                show_progress=True,  # æ˜¾ç¤ºè¿›åº¦
            )

            ids = [node.node_id for node in nodes]
            elapsed = time.time() - start_time
            embed_speed = len(nodes) / elapsed if elapsed > 0 else 0

            logger.info(f"[VectorStore] ========== åµŒå…¥å®Œæˆ ==========")
            logger.info(
                f"[VectorStore] âœ… æˆåŠŸåµŒå…¥ {len(nodes)} ä¸ªèŠ‚ç‚¹ | "
                f"è€—æ—¶: {elapsed:.2f} ç§’ | "
                f"é€Ÿåº¦: {embed_speed:.1f} èŠ‚ç‚¹/ç§’"
            )
            logger.info(f"[VectorStore] Added {len(nodes)} nodes successfully")

            # ç»“æŸ Span - è®°å½•åµŒå…¥æ“ä½œ
            if span:
                langfuse.end_span(
                    span,
                    output={
                        "num_nodes_added": len(nodes),
                        "node_ids": ids[:5],  # åªè®°å½•å‰5ä¸ª
                        "elapsed_seconds": round(elapsed, 3),
                    },
                )

            # è®°å½•åµŒå…¥æ“ä½œåˆ° Langfuse
            if trace and langfuse.enabled:
                langfuse.log_embedding(
                    trace=trace,
                    name="document_embedding",
                    model=settings.EMBEDDING_MODEL,
                    texts=[n.get_content()[:100] for n in nodes[:5]],
                    metadata={
                        "total_texts": len(nodes),
                        "collection": self.collection_name,
                    },
                )

            return ids

        except Exception as e:
            logger.error(f"[VectorStore] Failed to add nodes: {e}", exc_info=True)
            if span:
                langfuse.end_span(
                    span,
                    output={"error": str(e)},
                    level="ERROR",
                    status_message=str(e),
                )
            raise

    def add_documents(
        self,
        documents: List[LangchainDocument],
        overwrite: bool = False,
    ) -> List[str]:
        """
        æ·»åŠ  LangChain æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨ï¼ˆè‡ªåŠ¨è½¬æ¢ï¼‰ã€‚

        ä¿æŒä¸ LangChain çš„å…¼å®¹æ€§ã€‚

        Parameters
        ----------
        documents : List[LangchainDocument]
            LangChain Document åˆ—è¡¨

        overwrite : bool
            æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®

        Returns
        -------
        List[str]
            æ–‡æ¡£ ID åˆ—è¡¨

        Example
        -------
        ```python
        from langchain_core.documents import Document

        docs = [
            Document(page_content="å†…å®¹1", metadata={"source": "doc1"}),
            Document(page_content="å†…å®¹2", metadata={"source": "doc2"}),
        ]
        ids = manager.add_documents(docs)
        ```
        """
        if not documents:
            return []

        logger.info(
            f"[VectorStore] Converting {len(documents)} LangChain documents to nodes"
        )

        # è½¬æ¢ä¸º LlamaIndex TextNode
        nodes = [
            TextNode(
                text=doc.page_content,
                metadata=dict(doc.metadata) if doc.metadata else {},
            )
            for doc in documents
        ]

        return self.add_nodes(nodes, overwrite=overwrite)

    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        trace=None,
    ) -> List[NodeWithScore]:
        """
        æ£€ç´¢ç›¸ä¼¼èŠ‚ç‚¹ã€‚

        Parameters
        ----------
        query : str
            æŸ¥è¯¢æ–‡æœ¬

        top_k : int
            è¿”å›ç»“æœæ•°é‡

        trace : Langfuse Trace, optional
            Langfuse è¿½è¸ªå¯¹è±¡

        Returns
        -------
        List[NodeWithScore]
            å¸¦è¯„åˆ†çš„èŠ‚ç‚¹åˆ—è¡¨

        Example
        -------
        ```python
        results = manager.retrieve("å¦‚ä½•ç”³è¯·é€€æ¬¾ï¼Ÿ", top_k=5)
        for node in results:
            print(f"Score: {node.score:.4f}")
            print(f"Content: {node.node.get_content()[:100]}")
            print(f"Source: {node.node.metadata.get('source')}")
        ```
        """
        logger.info(f"[VectorStore] Retrieving - query: {query[:50]}..., k: {top_k}")

        # Langfuse è¿½è¸ª
        langfuse = get_langfuse_service()
        span = None
        if trace:
            span = langfuse.create_span(
                trace,
                name="vector_retrieval",
                input={
                    "query": query,
                    "top_k": top_k,
                },
                metadata={
                    "collection": self.collection_name,
                    "embedding_model": settings.EMBEDDING_MODEL,
                },
            )

        start_time = time.time()

        try:
            index = self._get_index()
            retriever = VectorIndexRetriever(
                index=index,
                similarity_top_k=top_k,
            )

            results = retriever.retrieve(query)
            elapsed = time.time() - start_time

            logger.info(f"[VectorStore] Retrieved {len(results)} nodes")
            for i, node in enumerate(results):
                source = node.node.metadata.get("source", "unknown")
                logger.debug(
                    f"[VectorStore] Node {i+1}: score={node.score:.4f}, "
                    f"source={source}"
                )

            # ç»“æŸ Span
            if span:
                langfuse.end_span(
                    span,
                    output={
                        "num_results": len(results),
                        "scores": [round(r.score, 4) for r in results],
                        "sources": [
                            r.node.metadata.get("source", "unknown")
                            for r in results
                        ],
                        "elapsed_seconds": round(elapsed, 3),
                    },
                )

            # è®°å½•æ£€ç´¢æ“ä½œ
            if trace and langfuse.enabled:
                langfuse.log_retrieval(
                    trace=trace,
                    name="vector_search",
                    query=query,
                    documents=[
                        {
                            "content": r.node.get_content()[:200],
                            "score": r.score,
                            "source": r.node.metadata.get("source", "unknown"),
                        }
                        for r in results
                    ],
                    metadata={
                        "top_k": top_k,
                        "collection": self.collection_name,
                    },
                )

            return results

        except Exception as e:
            logger.error(f"[VectorStore] Retrieve failed: {e}", exc_info=True)
            if span:
                langfuse.end_span(
                    span,
                    output={"error": str(e)},
                    level="ERROR",
                    status_message=str(e),
                )
            return []

    def similarity_search(
        self,
        query: str,
        k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
    ) -> List[LangchainDocument]:
        """
        LangChain å…¼å®¹çš„ç›¸ä¼¼åº¦æœç´¢ã€‚

        è¿”å› LangChain Document æ ¼å¼ï¼Œä¿æŒä¸æ—§ä»£ç çš„å…¼å®¹æ€§ã€‚

        Parameters
        ----------
        query : str
            æŸ¥è¯¢æ–‡æœ¬

        k : int
            è¿”å›ç»“æœæ•°é‡

        filter_dict : dict, optional
            å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆæš‚ä¸æ”¯æŒï¼‰

        Returns
        -------
        List[LangchainDocument]
            LangChain Document åˆ—è¡¨
        """
        logger.info(f"[VectorStore] similarity_search - query: {query[:50]}..., k: {k}")

        if filter_dict:
            logger.warning("[VectorStore] filter_dict not supported yet, ignoring")

        results = self.retrieve(query, top_k=k)

        # è½¬æ¢ä¸º LangChain Document
        documents = []
        for node_with_score in results:
            node = node_with_score.node
            doc = LangchainDocument(
                page_content=node.get_content(),
                metadata={
                    **dict(node.metadata),
                    "score": node_with_score.score,
                },
            )
            documents.append(doc)

        return documents

    def similarity_search_with_score(
        self,
        query: str,
        k: int = 5,
    ) -> List[tuple]:
        """
        å¸¦è¯„åˆ†çš„ç›¸ä¼¼åº¦æœç´¢ï¼ˆLangChain å…¼å®¹ï¼‰ã€‚

        Returns
        -------
        List[tuple]
            (Document, score) å…ƒç»„åˆ—è¡¨
        """
        logger.info(
            f"[VectorStore] similarity_search_with_score - query: {query[:50]}..., k: {k}"
        )

        results = self.retrieve(query, top_k=k)

        return [
            (
                LangchainDocument(
                    page_content=node.node.get_content(),
                    metadata=dict(node.node.metadata),
                ),
                node.score,
            )
            for node in results
        ]

    def get_retriever(self, search_kwargs: Optional[Dict] = None) -> "VectorStoreRetriever":
        """
        è·å– LangChain å…¼å®¹çš„æ£€ç´¢å™¨ã€‚

        Returns a proper BaseRetriever subclass for LCEL chain compatibility.

        Parameters
        ----------
        search_kwargs : dict, optional
            æœç´¢å‚æ•°ï¼Œå¦‚ {"k": 5}

        Returns
        -------
        VectorStoreRetriever
            LangChain BaseRetriever å®ç°
        """
        kwargs = search_kwargs or {"k": 5}
        k = kwargs.get("k", 5)

        return VectorStoreRetriever(manager=self, top_k=k)

    def delete_collection(self) -> bool:
        """
        åˆ é™¤é›†åˆã€‚

        Returns
        -------
        bool
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # é‡æ–°åˆ›å»ºä»¥æ¸…ç©ºæ•°æ®
            self._vector_store = None
            self._index = None
            self._get_vector_store(overwrite=True)
            logger.info(f"[VectorStore] Collection {self.collection_name} deleted")
            return True
        except Exception as e:
            logger.error(f"[VectorStore] Failed to delete collection: {e}")
            return False

    def get_collection_stats(self) -> Dict[str, Any]:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯ã€‚

        Returns
        -------
        dict
            åŒ…å«é›†åˆåç§°ã€å®ä½“æ•°ç­‰ä¿¡æ¯
        """
        try:
            from pymilvus import Collection, connections

            connections.connect(host=self.host, port=self.port)
            collection = Collection(self.collection_name)
            collection.load()

            stats = {
                "name": self.collection_name,
                "num_entities": collection.num_entities,
                "schema": str(collection.schema),
            }
            return stats

        except Exception as e:
            logger.error(f"[VectorStore] Failed to get stats: {e}")
            return {"error": str(e)}


# ==================== å…¨å±€å®ä¾‹ ====================

_vector_store_manager: Optional[VectorStoreManager] = None


def get_vector_store_manager() -> VectorStoreManager:
    """
    è·å–å…¨å±€å‘é‡å­˜å‚¨ç®¡ç†å™¨å®ä¾‹ã€‚

    Returns
    -------
    VectorStoreManager
        å‘é‡å­˜å‚¨ç®¡ç†å™¨å•ä¾‹
    """
    global _vector_store_manager
    if _vector_store_manager is None:
        _vector_store_manager = VectorStoreManager()
    return _vector_store_manager
